# Data Science Glossary

A collection of terms and definitions used across Data Science in PHS.

[A](#a) - [B](#b) - [C](#c) - [D](#d) - [E](#e) - [F](#f) - [G](#g) - [H](#h) - [I](#i) - [J](#j) - [K](#k) - [L](#l) - [M](#m) - [N](#n) - [O](#o) - [P](#p) - [Q](#q) - [R](#r) - [S](#s) - [T](#t) - [U](#u) - [V](#v) - [W](#w) - [X](#x) - [Y](#y) - [Z](#z)

## A

| Term | Definition |
| ---- | ---------- |
| **Accuracy** | The proportion of correct predictions made by a model. |
| **Algorithm** | A set of rules or steps to be followed in calculations or other problem-solving operations, especially by a computer. |
| **Apache Spark** | A unified analytics engine for large-scale data processing. |
| **API** | An application programming interface, a set of routines, protocols, and tools for building software applications. |
| **Artificial Intelligence** | The theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages. |
| **AutoML** | The process of automating the end-to-end process of applying machine learning to real-world problems. |

## B

| Term | Definition |
| ---- | ---------- |
| **Bayes' Theorem** | A mathematical equation for calculation of conditional probability, i.e., the probability of event B occurring given that related event A has already happened. |
| **Bias** | A systematic error in a model that causes it to consistently underestimate or overestimate the true value of the target variable. |
| **Big Data** | A term used to describe the large volume of data - both structured and unstructured - that inundates a business on a day-to-day basis. |

## C

| Term | Definition |
| ---- | ---------- |
| **Categorical** | A variable that can take on one of a limited, and usually fixed, number of possible values, assigning each individual or object to a particular group or category. |
| **Classification** | A supervised machine learning task where the goal is to predict the class of a given data point. |
| **Confidence Interval** | A range of values within which an unknown population parameter is expected to fall. |
| **Container** | A standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. |
| **Continuous** | A variable that can take on any numerical value within a given range. |
| **Cross-validation** | A technique used to evaluate the performance of a model on a dataset that was not used to train the model. |

## D

| Term | Definition |
| ---- | ---------- |
| **D3** | A JavaScript library for producing dynamic, interactive data visualisations in web browsers. |
| **Dashboard** | A visual display of the most important information needed to achieve one or more objectives; consolidated and arranged on a single screen so the information can be monitored at a glance. |
| **Data Engineering** | A focus on scaling data access within the organisation, working on data acquisition, collection, management, and storage - as well as setting up data pipelines and transforming data into high quality, usable data for use by other areas in the organisation. |
| **Data Lake** | A repository that holds a vast amount of raw data in its native format until it is needed. |
| **Data Science** | The application of scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data. |
| **Data Scientist** | A person who uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data. |
| **Data Visualisation** | The graphic representation of data. It involves producing images that communicate relationships among the represented data to viewers of the images. |
| **Data Warehouse** | A centralised repository of data that is structured for query and analysis. |
| **Database** | A collection of data organised in such a way that a computer program can quickly select desired pieces of data. |
| **Decision Tree** | A tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. |
| **Docker** | A set of platform as a service products that use OS-level virtualization to deliver software in packages called containers. |

## E

| Term | Definition |
| ---- | ---------- |
| **ELT** | Extract, Load, Transform. A data pipeline process where data is extracted from a source, loaded into a data warehouse, and then transformed into a format that is ready for analysis. |
| **ETL** | Extract, Transform, Load. A data pipeline process where data is extracted from a source, transformed into a format that is ready for analysis, and then loaded into a data warehouse. |
| **Evaluation** | The process of assessing the performance of a model. |

## F

| Term | Definition |
| ---- | ---------- |
| **Feature** | A variable used to predict the target variable. |

## G

| Term | Definition |
| ---- | ---------- |
| **Geospatial** | The study of data that has a geographic component. |
| **Git** | A version-control system for tracking changes in source code during software development. |
| **GitHub** | A web-based hosting service for version control using Git, providing additional tools for managing projects. |

## H

| Term | Definition |
| ---- | ---------- |
| **Hadoop** | A framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. |
| **Hypothesis** | A proposed explanation for a phenomenon. |

## I

| Term | Definition |
| ---- | ---------- |
| **IDE** | An integrated development environment, providing a place to develop code with supporting tools. |
| **Imputation** | The process of replacing missing values with substituted values. |

## J

| Term | Definition |
| ---- | ---------- |
| **JavaScript** | A high-level, interpreted programming language. |
| **Jupyter Notebook** | An open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. |

## K

| Term | Definition |
| ---- | ---------- |
| **K-Means** | A clustering algorithm that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean. |
| **K-Nearest Neighbours** | A non-parametric method used for classification and regression. In both cases, the input consists of the k closest training examples in the feature space. |
| **Kaggle** | A platform for predictive modelling and analytics competitions in which statisticians and data miners compete to produce the best models for predicting and describing the datasets uploaded by companies and users. |
| **Kubernetes** | An open-source system for automating deployment, scaling, and management of containerised applications. |

## L

| Term | Definition |
| ---- | ---------- |
| **Linear Regression** | A linear approach to modelling the relationship between a scalar response and one or more explanatory variables. |
| **Logistic Regression** | A statistical model that in its basic form uses a logistic function to model a binary dependent variable. |

## M

| Term | Definition |
| ---- | ---------- |
| **Machine Learning** | The study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. |
| **Markdown** | A lightweight markup language with plain text formatting syntax. |
| **Model** | A mathematical representation of a real-world process. |

## N

| Term | Definition |
| ---- | ---------- |
| **Natural Language Processing (NLP)** | A subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages. |
| **Neural Network** | A network or circuit of neurons, or in a modern sense, an artificial neural network, composed of artificial neurons or nodes. |
| **NoSQL** | A method for storing and retrieving data that is modeled in means other than the tabular relations used in relational databases. |

## O

| Term | Definition |
| ---- | ---------- |
| **Open Source** | Software for which the original source code is made freely available and may be redistributed and modified. |
| **Overfitting** | A model that models the training data too well. |

## P

| Term | Definition |
| ---- | ---------- |
| **P-value** | The probability of obtaining a result at least as extreme as the one observed, assuming that the null hypothesis is correct. |
| **Pipeline** | A sequence of data processing components. |
| **Posit** | [Posit](posit.co) is the company that produces Posit Workbench and other data science tools. |
| **Posit Connect** | A publishing platform for sharing applications, documents, notebooks, and dashboards created in R or Python. |
| **Posit Package Manager** | An internal package manager for R and Python. |
| **Posit Workbench** | A centralised data science platform giving access to RStudio, Jupyter, and VS Code [IDE](#i)s. | 
| **Prediction** | The process of using a trained model to make predictions on new data. |
| **Python** | A general-purpose programming language. |

## Q

| Term | Definition |
| ---- | ---------- |

## R

| Term | Definition |
| ---- | ---------- |
| **R** | A programming language and software environment for statistical computing and graphics. |
| **Reproducible Analytical Pipelines (RAP)** | A set of tools and processes that enable the creation of a pipeline that can be used to reproduce the results of an analysis. |
| **Regression** | A statistical process for estimating the relationships among variables. |
| **R Markdown** | A document format that combines the capabilities of the R programming language with the simplicity of Markdown syntax. |
| **RStudio** | An integrated development environment (IDE) for R. |

## S

| Term | Definition |
| ---- | ---------- |
| **Shell** | A command-line interpreter that provides a traditional Unix-like command line user interface. |
| **Shiny** | An R package that makes it easy to build interactive web applications with R. |
| **SQL** | A domain-specific language used in programming and designed for managing data held in a relational database management system. |
| **Statistical Process Control (SPC)** | A method of quality control which employs statistical methods to monitor and control a process. |
| **Supervised Learning** | A machine learning task where the goal is to predict the value of a target variable. |
| **Support Vector Machine** | A supervised machine learning model that uses classification algorithms for two-group classification problems. |

## T

| Term | Definition |
| ---- | ---------- |
| **Tableau** | A business intelligence and analytics software tool. |
| **Training** | The process of fitting a model to a dataset. |

## U

| Term | Definition |
| ---- | ---------- |

## V

| Term | Definition |
| ---- | ---------- |
| **Validation** | The process of assessing the performance of a model. |
| **Version Control** | A system that records changes to a file or set of files over time so that you can recall specific versions later. |

## W

| Term | Definition |
| ---- | ---------- |
| **Web Scraping** | The process of extracting data from websites. |
| **Workflow** | A sequence of steps or tasks that must be completed to achieve a goal. |
| **Wrangle** | To manipulate (data) into a usable form. |

## X

| Term | Definition |
| ---- | ---------- |

## Y

| Term | Definition |
| ---- | ---------- |

## Z

| Term | Definition |
| ---- | ---------- |
